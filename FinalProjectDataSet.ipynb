{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643c030a-5313-4869-ab8c-cc7628148f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iexfinance in c:\\users\\ericn\\anaconda3\\lib\\site-packages (0.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from iexfinance) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from iexfinance) (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from pandas->iexfinance) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from pandas->iexfinance) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from pandas->iexfinance) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from requests->iexfinance) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from requests->iexfinance) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from requests->iexfinance) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from requests->iexfinance) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->iexfinance) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install iexfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49853d59-ae93-4147-9b70-5ae1a3d51165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ericn\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf12b15-0ae9-4532-8804-1e3144bd5b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\ericn\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "444219f2-688d-402b-9642-f52268e7cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from datetime import date, timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from iexfinance.stocks import get_historical_data, get_historical_intraday, Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8290c9c0-c95b-4e98-a64a-9ce5e3a86710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IEX Finance API no longer offers a free version so this key will have to be replaced weekly when the free trial expires\n",
    "#public api key\n",
    "api_key = \"pk_f85211ff18244b6cb07ec6c9e37723f3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6eb15fec-3a91-4b04-bd63-aa227f8d0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers():\n",
    "    '''Returns an array of stock tickers from wikipedia.org/wiki/List_of_S%26P_500_companies'''\n",
    "    html_text = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\").text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    table = soup.find(\"table\", class_ = \"wikitable sortable\")\n",
    "    company_elements = table.find_all(\"a\", class_ = \"external text\")\n",
    "\n",
    "    tickers = []\n",
    "\n",
    "    for company_element in company_elements:\n",
    "        company = str(company_element.contents[0]).lower()\n",
    "        if company not in tickers:\n",
    "            tickers.append(company.upper())\n",
    "            \n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36e8e07d-29fd-45ef-9d73-8d0963faeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d9bc0f52-4e47-4a6f-a346-7863d91ff8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sorted_historical_csv(tickers):\n",
    "    '''Creates a sorted csv of historical stock data for the past 5 years for the given list of stock tickers'''\n",
    "    start = datetime(2018, 6, 4)\n",
    "    end = datetime(2023, 6, 4)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    data_frame_list = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df = get_historical_data(ticker, start, end, output_format='pandas', token=api_key)\n",
    "        df = df.drop([\"id\", \"subkey\", \"updated\", \"label\", \"change\", \"high\", \"fHigh\", \"uHigh\", \"low\", \"uLow\", \"fLow\"], axis=1)\n",
    "        data_frame_list.append(df)\n",
    "\n",
    "    df2 = pd.concat(data_frame_list)\n",
    "    df2 = df2.sort_values(by=[\"priceDate\"])\n",
    "    df2.insert(0, 'Helpers', range(0, len(df2)))\n",
    "    df2 = df2.set_index(\"priceDate\")\n",
    "    df2.to_csv(\"SP500DataSetDateSorted.csv\")\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3a0948-c842-4ac5-99f8-e483af03d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_stats_csv(tickers):\n",
    "    '''Creates a csv of stock statistics for the current past fiscal quarter for the given list of stock tickers'''\n",
    "    df3 = pd.DataFrame()\n",
    "    data_frame_list_2 = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df3 = Stock(ticker, token=api_key).get_key_stats()\n",
    "        data_frame_list_2.append(df3)\n",
    "\n",
    "    df4 = pd.concat(data_frame_list_2)\n",
    "    df4.to_csv(\"SP500DataSetKeyStats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9e29d9a5-25e6-4235-8a43-daf0aa36a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_sorted_historical_csv(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ea807e0c-340c-4895-8e5f-62e3889f061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data_set(to_be_updated, tickers, start_date=str((datetime.strptime(pd.read_csv(\"SP500DataSetDateSorted.csv\")[\"priceDate\"].iloc[-1], '%Y-%m-%d') + timedelta(days=1)))[0:10], today_date=date.today()):\n",
    "    '''Updates the given csv file to include the day after the last day already included to yesterdays date. Due to technical limitatons of the IEX Finance API, I was unable to find a way to use the get_historical_data function to pull stock data after the 4pm close as the API tracks after hours trading.'''\n",
    "    df = pd.DataFrame()\n",
    "    data_frame_list = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df = get_historical_data(ticker, start_date, today_date, output_format='pandas', token=api_key)\n",
    "        df = df.drop([\"id\", \"subkey\", \"updated\", \"label\", \"change\", \"high\", \"fHigh\", \"uHigh\", \"low\", \"uLow\", \"fLow\"], axis=1)\n",
    "        data_frame_list.append(df)\n",
    "\n",
    "    df2 = pd.concat(data_frame_list)\n",
    "    df2 = df2.sort_values(by=[\"priceDate\"])\n",
    "    df_prev = pd.read_csv(to_be_updated)\n",
    "    \n",
    "    df_merged = pd.concat([df_prev, df2])\n",
    "    \n",
    "    day = str(date.today()-relativedelta(years=5))\n",
    "    i = 1\n",
    "    \n",
    "    while True:\n",
    "        if df_merged.index[df_merged[\"priceDate\"].isin([day])==True].tolist() != []:\n",
    "            #Removes the same number of days from the dataframe that were added to the dataframe. \n",
    "            #The range for removal goes from the date of the first element to the date of the last element added minus 5 years.\n",
    "            #If that element doesn't exist, it will subtract one day and continue to do so until a valid day is found.\n",
    "            df_merged.drop(df_merged.index[int(df_merged.iloc[0][1]):int(df_merged.index[df_merged[\"priceDate\"].isin([day])==True].tolist()[0])], axis=0, inplace=True)\n",
    "            break\n",
    "        else:\n",
    "            day = str(date.today()-relativedelta(years=5)-timedelta(days=i))\n",
    "            if i == 5:\n",
    "                break\n",
    "            else:\n",
    "                i+=1\n",
    "        \n",
    "    df_merged = df_merged.drop([\"Helpers\"], axis=1)\n",
    "    df_merged.insert(0, \"Helpers\", range(0, len(df_merged)))\n",
    "    df_merged = df_merged.set_index(\"priceDate\")\n",
    "    df_merged.to_csv(\"SP500DataSetDateSortedUpdated\" + str(date.today()) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d88702b3-77ec-4349-9802-cefdbf5742b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data_set(\"SP500DataSetDateSorted.csv\", tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "100ddb5c-6d7f-4424-9162-7b52c4536a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = pd.read_csv(\"NYSE Listed.csv\")\n",
    "nyse_tickers = read_file[\"ACT Symbol\"].to_list()\n",
    "#create_sorted_historical_csv(nyse_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc057a7d-1425-4d92-8ed3-2425e26f5877",
   "metadata": {},
   "source": [
    "### Markowitz Efficient Frontier\n",
    "\n",
    "The Markowitz efficient frontier represents the boundary of the set of feasible portfolios (in this case portfolios consisting exclusively of equities) that have the maximum return for a given level of risk. Any portfolios above the frontier cannot be achieved. \n",
    "\n",
    "*Markowitz efficient frontier definition.* Nasdaq. (n.d.). https://www.nasdaq.com/glossary/m/markowitz-efficient-frontier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311528b0-f169-4ff3-9747-c07f8dc965a9",
   "metadata": {},
   "source": [
    "![alt text](mpt-image-2.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f15fb-88b3-4177-a7c3-0e6f1efc4fff",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "\n",
    "The Sharpe Ratio is a measurement of the risk adjusted return of an asset compared to an asset with zero risk. While assets with zero risk only exist theoretically, near risk-free assets do exist and are used to calculate the risk-free rate. The most common method is to take the return of United States Treasury bonds over the same duration as the other asset and subtract the current rate of inflation. \n",
    "\n",
    "Sharpe, W. F. (n.d.). *The Sharpe Ratio.* The Sharpe Ratio. http://web.stanford.edu/~wfsharpe/art/sr/sr.htm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797436a-6b5d-4a44-9004-e86b4b993b11",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "$Sharpe Ratio = \\frac{R_p - R_f}{\\sigma_p}$\n",
    "\n",
    "$R_p$ = return of portfolio \\\n",
    "$R_f$ = risk free rate \\\n",
    "$\\sigma_p$ = standard deviation of the portfolio's excess return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95881384-b383-4c49-8da7-b4be85bdd6ee",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory Networks (LSTM)\n",
    "\n",
    "LSTM stands for short term memory networks. It a type of recurrent neural network (RNN) that is capable of processing both individual data points as well as sequences of data. \"The central role of an LSTM model is held by a memory cell known as a ‘cell state’ that maintains its state over time. It can be visualized as a conveyor belt through which information just flows, unchanged. nformation can be added to or removed from the cell state in LSTM and is regulated by gates. These gates optionally let the information flow in and out of the cell. It contains a pointwise multiplication operation and a sigmoid neural net layer that assist the mechanism. The sigmoid layer gives out numbers between zero and one, where zero means ‘nothing should be let through’, and one means ‘everything should be let through.'\"  \n",
    "\n",
    "What is LSTM - introduction to long short term memory. Intellipaat Blog. (2023, June 13). https://intellipaat.com/blog/what-is-lstm/?US#:~:text=The%20central%20role%20of%20an,which%20information%20just%20flows%2C%20unchanged. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
